{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio.windows_events import NULL\n",
    "from itertools import product\n",
    "from multiprocessing.sharedctypes import Value\n",
    "from socket import socket\n",
    "from tkinter import N\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import urllib.request\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n",
    "    TimeSeriesResampler\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize']=20,10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dropout,Dense\n",
    "\n",
    "#Câu 1\n",
    "# Lấy 100 mã chứng khoán tại trang web cafef.vn\n",
    "def getData():\n",
    "    #Truy cập vào trnag web với đường dẫn ulr (ở đây là trang web cafef.vn )\n",
    "    url =  f'https://s.cafef.vn/TraCuuLichSu2/3/HOSE/01/01/2020.chn'\n",
    "    page = urllib.request.urlopen(url)\n",
    "    #Phân tích cú pháp trang web bằng thư viện BeautifulSoup\n",
    "    soup = BS(page, 'html.parser')\n",
    "    list1 = []\n",
    "    for i in range(0,100):\n",
    "        #Sử dụng thuộc tính .find để tìm dữ liệu cần trích xuất\n",
    "        Stock = soup.find('table',id='table2sort').findAll('td',class_='CodeItem')[i].find('a',class_='symbol')\n",
    "        list1.append(Stock.get_text())\n",
    "\n",
    "\n",
    "    return list1\n",
    "\n",
    "#Lấy giá hàng ngày (giá đóng) của 100 mã trên tại trang web cophieu68.vn\n",
    "def Ngay_dongcua():\n",
    "    list_date = []\n",
    "    for i in range(1,7):\n",
    "        url = f'https://www.cophieu68.vn/historyprice.php?currentPage={i}&id=aaa'\n",
    "\n",
    "        page = urllib.request.urlopen(url)\n",
    "        soup = BS(page, 'html.parser')\n",
    "        Stock = soup.find('div', id = 'content').find('table', class_ = 'stock').findAll('tr')\n",
    "\n",
    "        for i in range(1,len(Stock)):\n",
    "            if (len(Stock[i].findAll('td')) > 1):\n",
    "                Date = Stock[i].findAll('td')[1].get_text().replace('\\n','')\n",
    "                Product_date = []\n",
    "                Product_date.append(Date)\n",
    "                list_date.append(Product_date)   \n",
    "    \n",
    "       \n",
    "    return list_date\n",
    "\n",
    "def Gia_dongcua():\n",
    "    list_dateofStock = Ngay_dongcua()\n",
    "    list_ma = getData() \n",
    "    list_100 = []\n",
    "    \n",
    "    #Tạo ra 100 list nhỏ bỏ vào list_100 để chưa giá trị từng mã cổ phiếu\n",
    "    for i in range(100):\n",
    "        list_100.append([])\n",
    "    \n",
    "    \n",
    "    for j in range(1,7):\n",
    "        for code in getData():\n",
    "            value_code = \"\".join(code)\n",
    "            url = f'https://www.cophieu68.vn/historyprice.php?currentPage={j}&id={code}'\n",
    "\n",
    "            page = urllib.request.urlopen(url)\n",
    "            soup = BS(page, 'html.parser')\n",
    "            Stock = soup.find('div', id = 'content').find('table', class_ = 'stock').findAll('tr')\n",
    "\n",
    "            for i in range(1,len(Stock)):\n",
    "                if (len(Stock[i].findAll('td')) > 1):\n",
    "                    Price = Stock[i].findAll('td')[5].get_text().replace('\\n','')\n",
    "                    Date = Stock[i].findAll('td')[1].get_text().replace('\\n','')\n",
    "                   \n",
    "                    for i in range(0,100):\n",
    "                        value = \"\".join(list_ma[i])\n",
    "                        if (value_code == value):\n",
    "                            Product = Price\n",
    "                            # Product.append(Price)\n",
    "                            Product = float(Product)\n",
    "                            list_100[i].append(Product)\n",
    "\n",
    "     #Lưu trữ dữ liệu mới thu thập được dứơi định dạng DataFrame\n",
    "    df = pd.DataFrame({'Date':list_dateofStock, 'HGP': list_100[0], 'E1VFVN30': list_100[1], 'HAI': list_100[2], 'DLG': list_100[3], 'FIT': list_100[4],\n",
    "    'FLT':list_100[5], 'HQC':list_100[6], 'GEX':list_100[7], 'PVD':list_100[8], 'MSN':list_100[9], 'PVI':list_100[10],'VRE':list_100[11],'DXG':list_100[12],\n",
    "    'SJF':list_100[13],'AMD':list_100[14],'VHM':list_100[15],'EVG':list_100[16],'HVN':list_100[17],'SCR':list_100[18],'SFG':list_100[19],'VGC':list_100[20],\n",
    "    'BFC':list_100[21],'TCH':list_100[22],'PHR':list_100[23],'BVH':list_100[24],'TDM':list_100[25],'HAH':list_100[26],'KSB':list_100[27],'SKG':list_100[28],\n",
    "    'BCM':list_100[29],'VNS':list_100[30],'CNG':list_100[31],'TTB':list_100[32],'LPB':list_100[33],'DAH':list_100[34],'HTN':list_100[35],'NHA':list_100[36],\n",
    "    'CSV':list_100[37],'DHG':list_100[38],'SVC':list_100[39],'IJC':list_100[40],'FPT':list_100[41],'DVP':list_100[42],'C32':list_100[43],'BIC':list_100[44],\n",
    "    'BMC':list_100[45],'STB':list_100[46],'SCD':list_100[47],'HCD':list_100[48],'CTS':list_100[49],'MSH':list_100[50],'TNI':list_100[51],'BMP':list_100[52],\n",
    "    'NSC':list_100[53],'HBC':list_100[54],'SFI':list_100[55],'UIC':list_100[56],'SAV':list_100[57],'TVB':list_100[58],'LIX':list_100[59],'FMC':list_100[60],\n",
    "    'GMC':list_100[61],'FVN':list_100[62],'NHH':list_100[63],'VHC':list_100[64],'DGC':list_100[65],'HSG':list_100[66],'VTB':list_100[67],'SMB':list_100[68],\n",
    "    'CLC':list_100[69],'HDC':list_100[70],'TVS':list_100[71],'IDI':list_100[72],'DHA':list_100[73],'APC':list_100[74],'FCM':list_100[75],'ACC':list_100[76],\n",
    "    'BMI':list_100[77],'GVR':list_100[78],'FUCVREIT':list_100[79],'DSN':list_100[80],'TNA':list_100[81],'CMX':list_100[82],'TCL':list_100[83],'DQC':list_100[84],\n",
    "    'GSP':list_100[85],'PME':list_100[86],'PET':list_100[87],'PJT':list_100[88],'LBM':list_100[89],'PAC':list_100[90],'SZL':list_100[91],'GDT':list_100[92],\n",
    "    'KHP':list_100[93],'GIL':list_100[94],'PGC':list_100[95],'MCG':list_100[96],'FUESSV50':list_100[97],'PAN':list_100[98],'VSH':list_100[99]})\n",
    "    \n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    #Lưu trữ dữ liệu mới thu thập được dưới định dạng CSV\n",
    "    df.to_csv('liststock_100.csv',index=False)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Câu 2\n",
    "# Chuẩn hóa dữ liệu và sử dụng phương pháp min-max\n",
    "def cau2():\n",
    "    #Lấy dữ liệu từ file csv\n",
    "    dtf = pd.read_csv('./liststock_100.csv')\n",
    "    \n",
    "    #Lấy giá trị của 5 mã đầu tiên tương ứng với 5 cột đầu tiên\n",
    "    dtf1 = dtf.iloc[:,0:5]\n",
    "\n",
    "    #Vẽ biểu đồ đường của 5 mã khi chưa chuẩn hóa\n",
    "#     dtf1.plot(figsize=(15,6))\n",
    "    \n",
    "    col = dtf1.columns\n",
    "    \n",
    "    #Sử dụng MinMaxScaler để chia tỷ lệ dữ liệu thành phạm vi [0,1]\n",
    "    min_max_Scalar = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    #Phù hợp vs dữ liệu sau đó biến đổi nó\n",
    "    result = min_max_Scalar.fit_transform(dtf1)\n",
    "    \n",
    "    result.mean(axis=0)\n",
    "    \n",
    "    result.std(axis=0)\n",
    "    \n",
    "    min_max_Scalar_df = pd.DataFrame(result, columns=col)\n",
    "    \n",
    "    #Vẽ biểu đồ đường của 5 mã khi đã chuẩn hóa  \n",
    "#     min_max_Scalar_df.plot(figsize = (15,6))\n",
    "    \n",
    "    return min_max_Scalar_df\n",
    "\n",
    "\n",
    "def Elbow():\n",
    "    #Lấy dữ liệu đã được normolize từ hàm cau2\n",
    "    dtf = cau2()\n",
    "    \n",
    "    dtf1 = dtf\n",
    "    #Lưu dữ liệu lấy được dưới định dạng DataFrame\n",
    "    dtf1 = pd.DataFrame(dtf1)\n",
    "    \n",
    "    losses = []\n",
    "    #chạy K-means cho các cụm bằng cách sử dùng vòng lặp for \n",
    "    #và thu thập các losses (biến dạng) vào một danh sách \n",
    "    for i in range(1,10):\n",
    "       \n",
    "        k_mean = KMeans(n_clusters = i)\n",
    "        \n",
    "        k_mean.fit(dtf1)\n",
    "        \n",
    "        losses.append(k_mean.inertia_)\n",
    "    #vẽ biểu đồ để xác định k       \n",
    "    plt.plot([1,2,3,4,5,6,7,8,9], losses, marker='*')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Câu 3\n",
    "# Sử dụng Time series k-means với 3 thực thể để phân nhóm giá cổ phiếu hàng ngày\n",
    "# của các mã cổ phiếu đó (5 mã normalize ở câu 2) \n",
    "\n",
    "def cau3():\n",
    "    #Lấy dữ liệu đã được normolize ở hàm cau2\n",
    "    dtf = cau2()\n",
    "    \n",
    "    #Lưu dữ liệu lấy được dưới định dạng DataFrame     \n",
    "    dtf1 = pd.DataFrame(dtf)\n",
    "    \n",
    "    #Chuyển đổi khung dữ liệu từ Pandas thành một mảng Numpy\n",
    "    dtf2 = dtf1.to_numpy()    \n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(dtf2)\n",
    "    \n",
    "    # Chỉ giữ 600 chuỗi thời gian\n",
    "    dtf2 = TimeSeriesScalerMeanVariance().fit_transform(dtf2[:600])\n",
    "\n",
    "    # Làm cho chuỗi thời gian ngắn hơn\n",
    "    dtf2 = TimeSeriesResampler(sz=600).fit_transform(dtf2)\n",
    "    sz = dtf2.shape[1]\n",
    "\n",
    "    #Time series k-means với thực thể Distance Euclidean k-means\n",
    "    print(\"Euclidean k-means\")\n",
    "    \n",
    "    #Phân cụm dữ liệu cho chuỗi thời gian với thực thể euclidean\n",
    "    km = TimeSeriesKMeans(n_clusters=3, verbose=True, random_state=seed)\n",
    "    \n",
    "    #Điều chỉnh phân cụm k-mean bằng cách sử dụng phân cụm\n",
    "    #Trên tập dữ liệu và sau đó dự đoán cụm gần nhất mà mỗi chuỗi thời gian trong tập dữ liệu thuộc về\n",
    "    y_pred = km.fit_predict(dtf2)\n",
    "\n",
    "    plt.figure()\n",
    "    for yi in range(3):\n",
    "        #Vẽ biểu đồ gồm 3 hàng, 3 cột và yi_1 chỉ số của đồ thị\n",
    "        plt.subplot(3, 3, yi + 1)\n",
    "        for xx in dtf2[y_pred == yi]:\n",
    "            plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "        plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "        plt.xlim(0, sz)\n",
    "        plt.ylim(-4, 4)\n",
    "        \n",
    "        #Biến đổi mặc định chỉ định text nằm trong các chuỗi dữ liệu\n",
    "        plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n",
    "                 transform=plt.gca().transAxes)\n",
    "        if yi == 1:\n",
    "            plt.title(\"Euclidean $k$-means\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Time series k-means với thực thể DBA-k-means\n",
    "    print(\"DBA k-means\")\n",
    "    \n",
    "    #Phân cụm dữ liệu cho chuỗi thời gian bằng cách sử dụng thực thể BDA\n",
    "    dba_km = TimeSeriesKMeans(n_clusters=3,\n",
    "                              n_init=2,\n",
    "                              metric=\"dtw\",\n",
    "                              verbose=True,\n",
    "                              max_iter_barycenter=10,\n",
    "                              random_state=seed)\n",
    "    \n",
    "    #Điều chỉnh phân cụm K-mean bằng cách sử dụng phân cụm\n",
    "    #Trên tập dữ liệu và sau đó dự đoán cụm gần nhất mà mỗi chuỗi thời gian trong tập dữ liệu thuộc về\n",
    "    y_pred = dba_km.fit_predict(dtf2)\n",
    "\n",
    "    for yi in range(3):\n",
    "        #Vẽ biểu đồ gồm 3 hàng, 3 cột và chỉ số 4 + yi của đồ thị\n",
    "        plt.subplot(3, 3, 4 + yi)\n",
    "        for xx in dtf2[y_pred == yi]:\n",
    "            plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "        plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "        plt.xlim(0, sz)\n",
    "        plt.ylim(-4, 4)\n",
    "        plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n",
    "                 transform=plt.gca().transAxes)\n",
    "        if yi == 1:\n",
    "            plt.title(\"DBA $k$-means\")\n",
    "    plt.show()\n",
    "    \n",
    "    #Time series k-mean với thực thể Soft-DTW-k-means\n",
    "    print(\"Soft-DTW k-means\")\n",
    "    \n",
    "    #Phân cụm dữ liệu cho chuỗi thời gian với thực thể Soft-DTW\n",
    "    sdtw_km = TimeSeriesKMeans(n_clusters=3,\n",
    "                               metric=\"softdtw\",\n",
    "                               metric_params={\"gamma\": .01},\n",
    "                               verbose=True,\n",
    "                               random_state=seed)\n",
    "     #Điều chỉnh phân cụm K-mean bằng cách sử dụng phân cụm\n",
    "    #Trên tập dữ liệu và sau đó dự đoán cụm gần nhất mà mỗi chuỗi thời gian trong tập dữ liệu thuộc về\n",
    "    y_pred = sdtw_km.fit_predict(dtf2)\n",
    "\n",
    "    for yi in range(3):\n",
    "        #Vẽ biểu đồ gồm 3 hàng, 3 cột và yi+7 chỉ số của đồ thị\n",
    "        plt.subplot(3, 3, 7 + yi)\n",
    "        for xx in dtf2[y_pred == yi]:\n",
    "            plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "        plt.plot(sdtw_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "        plt.xlim(0, sz)\n",
    "        plt.ylim(-3, 3)\n",
    "        plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n",
    "                 transform=plt.gca().transAxes)\n",
    "        if yi == 1:\n",
    "            plt.title(\"Soft-DTW $k$-means\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def cau4():\n",
    "    #Lấy dữ liệu từ hàm Gia_dongcua\n",
    "    dtf = Gia_dongcua()\n",
    "\n",
    "    #Lưu dữ liệu lấy được dưới định dạng DataFrame\n",
    "    df1 = pd.DataFrame(dtf)\n",
    "    #Lấy ra những giá đống cửa hàng ngày của mã HGP\n",
    "    df = df1[\"HGP\"]\n",
    "    #Lưu dữ liệu lấy được của mã HGP dưới định dạng DataFrame\n",
    "    df2 = pd.DataFrame(df)\n",
    "    #Sắp xếp lại cột chỉ sớ của DataFrame cho dữ liệu trên\n",
    "    df2.reset_index(inplace = True)\n",
    "    #Chuyển đổi dữ liệu \"Date\" sang loại ngày giờ\n",
    "    df2[\"Date\"] = pd.to_datetime(df2.Date, format=\"['%d-%m-%Y']\")\n",
    "    df2.dtypes\n",
    "    #Chỉ định giá trị chỉ mục của khung dữ liệu là cột ngày\n",
    "    df2.index = df2['Date']\n",
    "    df3 = df2[:550]\n",
    "    #vẽ biểu đồ đường để đưa ra ý tưởng về sự thay đổi giá cổ phiếu trong 1 năm \n",
    "    plt.plot(df3[\"HGP\"],label='Close Price history')\n",
    "    #điều chỉnh cơ bản trên dữ liệu - chuẩn bị dữ liệu\n",
    "    df3 = df3.sort_index(ascending=True,axis=0)\n",
    "    data = pd.DataFrame(index=range(0,len(df3)),columns=['Date','HGP'])\n",
    "    for i in range(0,len(data)):\n",
    "        data[\"Date\"][i]=df3['Date'][i]\n",
    "        data[\"HGP\"][i]=df3[\"HGP\"][i]\n",
    "\n",
    "\n",
    "    # Tiền xử lý dữ liệu băng cách chia dữ liệu theo phương pháp max-min normalization \n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    data.index=data.Date\n",
    "    data.drop(\"Date\",axis=1,inplace=True)\n",
    "    final_data = data.values \n",
    "    train_data=final_data[0:500,:]\n",
    "    valid_data=final_data[500:,:]\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data=scaler.fit_transform(final_data)\n",
    "    #Chuyển đổi một mãng giá trị thành một ma trận tập dữ liệu\n",
    "    x_train_data,y_train_data=[],[]\n",
    "    for i in range(60,len(train_data)):\n",
    "        x_train_data.append(scaled_data[i-60:i,0])\n",
    "        y_train_data.append(scaled_data[i,0])\n",
    "    x_train_data = np.asarray(x_train_data)\n",
    "    y_train_data = np.asarray(y_train_data)\n",
    "\n",
    "\n",
    "\n",
    "    # Sử dụng mô hình LSTM (bộ nhớ ngắn dài hạn)\n",
    "    # Tạo mô hình thực tiễn\n",
    "    lstm_model=Sequential()\n",
    "    lstm_model.add(LSTM(units=20,return_sequences=True,input_shape=(np.shape(x_train_data)[1],1)))\n",
    "    lstm_model.add(LSTM(units=20))\n",
    "    lstm_model.add(Dense(1)) #Dense được sử dụng làm lớp đầu ra\n",
    "    model_data=data[len(data)-len(valid_data)-60:].values\n",
    "    model_data=model_data.reshape(-1,1)\n",
    "    model_data=scaler.transform(model_data)\n",
    "\n",
    "    \n",
    "    # Chuẩn bị dữ liệu đạo tạo và dữ liệu thử nghiệm\n",
    "    lstm_model.compile(loss='mean_squared_error',optimizer='adam') #Biên dịch mô hình\n",
    "    #Huấn luyện mô hình\n",
    "    lstm_model.fit(x_train_data,y_train_data,epochs=1,batch_size=1,verbose=2)\n",
    "    X_test=[]\n",
    "    for i in range(60,model_data.shape[0]):\n",
    "        X_test.append(model_data[i-60:i,0])\n",
    "    X_test=np.array(X_test)\n",
    "    #Reshape(định hình) lại đầu vào thành [samples, time steps, features]\n",
    "    X_test=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "\n",
    "    #dự đoán - chạy mô hình bằng cách sử dụng dữ liệu thử nghiệm đã đượ\n",
    "    predicted_stock_price=lstm_model.predict(X_test)\n",
    "    predicted_stock_price=scaler.inverse_transform(predicted_stock_price)\n",
    "    #Kiểm tra độ chính xác của mô hình. \n",
    "    train_data=data[:500]\n",
    "    valid_data=data[500:]\n",
    "    valid_data['Predictions']=predicted_stock_price\n",
    "    #Vẽ biểu đồ \n",
    "    plt.plot(train_data[\"HGP\"])\n",
    "    plt.plot(valid_data[[\"Predictions\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c4b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
